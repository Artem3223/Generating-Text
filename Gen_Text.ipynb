{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\artm-\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\artm-\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\artm-\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\artm-\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\artm-\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\artm-\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\artm-\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\artm-\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\artm-\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\artm-\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\artm-\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\artm-\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 600901\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "path = keras.utils.get_file('nietzsche.txt',\n",
    "                            origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "\n",
    "text = open(path).read().lower()\n",
    "print('Corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 60 # Извлечение последовательностей по 60 символов\n",
    "step = 3 # Новые последовательности выбираются через каждые 3 символа\n",
    "sentences = [] # Хранение извлеченных последовательностей\n",
    "next_chars = [] # Хранение целей (символов, следующих за последовательностями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 200281\n",
      "Unique characters: 59\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Number of sequences:', len(sentences))\n",
    "chars = sorted(list(set(text))) # Список уникальных символов в корпусе\n",
    "print('Unique characters:', len(chars))\n",
    "char_indices = dict((char, chars.index(char)) for char in chars) # Словарь, отображающий уникальные символы в их индексы в списке «chars»\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "        y[i, char_indices[next_chars[i]]] = 1 # Прямое кодирование символов в бинарные массивы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "WARNING:tensorflow:From C:\\Users\\artm-\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 74s 368us/step - loss: 1.9588\n",
      "epoch 2\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 73s 367us/step - loss: 1.6163\n",
      "epoch 3\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 74s 371us/step - loss: 1.5259\n",
      "epoch 4\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 77s 385us/step - loss: 1.4797\n",
      "epoch 5\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 77s 386us/step - loss: 1.4494\n",
      "epoch 6\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 77s 387us/step - loss: 1.4261\n",
      "epoch 7\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 79s 393us/step - loss: 1.4077\n",
      "epoch 8\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 76s 381us/step - loss: 1.3931\n",
      "epoch 9\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 73s 366us/step - loss: 1.38290s - loss: 1.383\n",
      "epoch 10\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 74s 371us/step - loss: 1.3717\n",
      "epoch 11\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 76s 378us/step - loss: 1.3628\n",
      "epoch 12\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 75s 375us/step - loss: 1.3551\n",
      "epoch 13\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 75s 372us/step - loss: 1.3482\n",
      "epoch 14\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 74s 368us/step - loss: 1.3415\n",
      "epoch 15\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 74s 368us/step - loss: 1.33670s - loss\n",
      "epoch 16\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 73s 366us/step - loss: 1.3327\n",
      "epoch 17\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 357us/step - loss: 1.3263\n",
      "epoch 18\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 357us/step - loss: 1.3233\n",
      "epoch 19\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 355us/step - loss: 1.3200\n",
      "epoch 20\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 72s 357us/step - loss: 1.3146\n",
      "epoch 21\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 357us/step - loss: 1.3128\n",
      "epoch 22\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 355us/step - loss: 1.3093\n",
      "epoch 23\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 354us/step - loss: 1.3054\n",
      "epoch 24\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 355us/step - loss: 1.3018\n",
      "epoch 25\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 356us/step - loss: 1.2992\n",
      "epoch 26\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 356us/step - loss: 1.2955\n",
      "epoch 27\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 72s 357us/step - loss: 1.29230s - loss: 1.29\n",
      "epoch 28\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 357us/step - loss: 1.2895\n",
      "epoch 29\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 357us/step - loss: 1.2880\n",
      "epoch 30\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 357us/step - loss: 1.2849\n",
      "epoch 31\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 357us/step - loss: 1.2834\n",
      "epoch 32\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 355us/step - loss: 1.2800\n",
      "epoch 33\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 356us/step - loss: 1.2773\n",
      "epoch 34\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 357us/step - loss: 1.2756\n",
      "epoch 35\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 357us/step - loss: 1.2736\n",
      "epoch 36\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 356us/step - loss: 1.2725\n",
      "epoch 37\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 356us/step - loss: 1.2697\n",
      "epoch 38\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 356us/step - loss: 1.2689\n",
      "epoch 39\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 357us/step - loss: 1.2679\n",
      "epoch 40\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 357us/step - loss: 1.26560s - loss: 1.265\n",
      "epoch 41\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 356us/step - loss: 1.2631\n",
      "epoch 42\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 355us/step - loss: 1.2626\n",
      "epoch 43\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 72s 358us/step - loss: 1.2601\n",
      "epoch 44\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 356us/step - loss: 1.25831s - - ETA: 0s - loss: \n",
      "epoch 45\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 356us/step - loss: 1.2555\n",
      "epoch 46\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 356us/step - loss: 1.2539\n",
      "epoch 47\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 357us/step - loss: 1.2521\n",
      "epoch 48\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 355us/step - loss: 1.2516\n",
      "epoch 49\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 356us/step - loss: 1.2512\n",
      "epoch 50\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 72s 357us/step - loss: 1.2492\n",
      "epoch 51\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 356us/step - loss: 1.2479\n",
      "epoch 52\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 356us/step - loss: 1.2470\n",
      "epoch 53\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 356us/step - loss: 1.2447\n",
      "epoch 54\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 356us/step - loss: 1.24451s\n",
      "epoch 55\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 355us/step - loss: 1.2425\n",
      "epoch 56\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 355us/step - loss: 1.2409: 0s - los\n",
      "epoch 57\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 355us/step - loss: 1.2410\n",
      "epoch 58\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 355us/step - loss: 1.2386\n",
      "epoch 59\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 71s 355us/step - loss: 1.2363\n",
      "--- Generating with seed: \"t something refined and noble into the\n",
      "tenets of his teacher\"\n",
      "------ temperature: 0.2\n",
      "t something refined and noble into the\n",
      "tenets of his teachers and the spirit of the sense of the sense of the spirit of the spiritual case, and the presence of the stronger and the moral themselves and the spirit of the spirit and soul--and the sense of the fact that it is the state of the condition of the spirit with the fact that it is not to be a superiority and conscience the fact that it is such an attain of the state of the spiritual the sense of the------ temperature: 0.5\n",
      "uch an attain of the state of the spiritual the sense of the eye of the bad in all conditions to the individual to a standing has at the lack of an interesting seriousness of the counter morality in the fashion of the sense of the scholaring and the world and moral them and the common, the spirit and historical indifference which is to serve of the compared\n",
      "of the present of the family in old truth of the spirit and another the fact that the most lighter p------ temperature: 1.0\n",
      "h of the spirit and another the fact that the most lighter praises or good and contimable\n",
      "with a whole mockeofy.\n",
      "the dospes of ears\n",
      "which has not\n",
      "such great all at the\n",
      "viridus superstition of this trigeacus is, still no mals.\n",
      "\n",
      "\n",
      "rothes of the dreads of the gives religious moral has yet deceal historically specially\n",
      "his coiver\n",
      "passing of morality.\n",
      "\n",
      "naturally intentale or speciable; the\n",
      "bad togethers, are the (nefforady polising, to\n",
      "societ, and a deno, be adv------ temperature: 1.2\n",
      ", are the (nefforady polising, to\n",
      "societ, and a deno, be advobuments, called. as should be question; teles for\n",
      "itherts decede, when nke! how there is, with bead? they\n",
      "=pisssation\n",
      "are has noble hand, if we ferts of lvquele: i a mancerive with retain than in soversed pedaeting, however, let to  the actual requiremel\n",
      "domain to our science.\n",
      "cerest call .=quitt. thus have other pariwiver longing. \"i speaks even pages? but\n",
      "as moral phy inclinance of delided, a s"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "for epoch in range(1, 60): # Обучение модели в течение 60 эпох\n",
    "    print('epoch', epoch)\n",
    "    model.fit(x, y, batch_size=128, epochs=1) # Выполнение одной итерации обучения\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "generated_text = text[start_index: start_index + maxlen]\n",
    "print('--- Generating with seed: \"' + generated_text + '\"')\n",
    "for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "    print('------ temperature:', temperature)\n",
    "    sys.stdout.write(generated_text)\n",
    "    for i in range(400):# Генерация 400 символов, начиная с начального текста\n",
    "        sampled = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(generated_text):\n",
    "            sampled[0, t, char_indices[char]] = 1.\n",
    "        \n",
    "        preds = model.predict(sampled, verbose=0)[0] # Выбор следующего символа\n",
    "        next_index = sample(preds, temperature)\n",
    "        next_char = chars[next_index]\n",
    "        \n",
    "        generated_text += next_char\n",
    "        generated_text = generated_text[1:]\n",
    "        \n",
    "        sys.stdout.write(next_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
